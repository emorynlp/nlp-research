# Papers in 2022

For each week, replace your name with one paper using the following format:

* [The Stem Cell Hypothesis: Dilemma behind Multi-Task Learning with Transformer Encoders](https://aclanthology.org/2020.iwpt-1.19/). He, Han and Choi, Jinho D. Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP), 2021.


### 03/07/2022

* [Can You Unpack That? Learning to Rewrite Questions-in-Context](https://aclanthology.org/D19-1605.pdf) Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)
* [Language model as an annotator: Exploring dialogpt for dialogue summarization](https://aclanthology.org/2021.acl-long.117.pdf). Feng et al. Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), 2021.
* [Probing the Robustness of Trained Metrics for Conversational Dialogue Systems](https://arxiv.org/abs/2202.13887). Deriu et al. arXiv, 2022.
* [Template-Based Named Entity Recognition Using BART](https://arxiv.org/pdf/2106.01760.pdf). Leyang Cui, Yu Wu, Jian Liu, Sen Yang, Yue Zhang, Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021
* [Capturing global informativeness in open domain keyphrase extraction](https://arxiv.org/abs/2004.13639). Sun et al. InCCF International Conference on Natural Language Processing and Chinese Computing, 2021.
* Liayn Xu
* [A Survey of Pretrained Language Models Based Text Generation](https://arxiv.org/pdf/2201.05273.pdf). Li et al. arXiv, 2022.

### 03/14/2022

* [TOD-BERT: Pre-trained Natural Language Understanding for Task-Oriented Dialogue](https://aclanthology.org/2020.emnlp-main.66.pdf) Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)
* James Finch
* Sarah Finch
* [Ask me anything: Dynamic memory networks for natural language processing](https://arxiv.org/pdf/1506.07285.pdf). Kumar, Ankit, et al. *International conference on machine learning*. PMLR, 2016.
* Sichang Tu
* Liayn Xu
* [Controlling the Focus of Pretrained Language Generation Models](https://arxiv.org/pdf/2203.01146.pdf). Ji et al. arXiv, 2022.

### 03/21/2022

* Kaustubh Dhole
* James Finch
* Sarah Finch
* Han He
* Sichang Tu
* Liayn Xu
* Zihao Wang

### 03/28/2022

* Kaustubh Dhole
* James Finch
* Sarah Finch
* Han He
* Sichang Tu
* Liayn Xu
* Zihao Wang

### 04/04/2022

* Kaustubh Dhole
* James Finch
* Sarah Finch
* Han He
* Sichang Tu
* Liayn Xu
* Zihao Wang

### 04/11/2022

* Kaustubh Dhole
* James Finch
* Sarah Finch
* Han He
* Sichang Tu
* Liayn Xu
* Zihao Wang

### 04/18/2022

* Kaustubh Dhole
* James Finch
* Sarah Finch
* Han He
* Sichang Tu
* Liayn Xu
* Zihao Wang

### 04/25/2022

* Kaustubh Dhole
* James Finch
* Sarah Finch
* Han He
* Sichang Tu
* Liayn Xu
* Zihao Wang

### 05/02/2022

* Kaustubh Dhole
* James Finch
* Sarah Finch
* Han He
* Sichang Tu
* Liayn Xu
* Zihao Wang

### 05/09/2022

* Kaustubh Dhole
* James Finch
* Sarah Finch
* Han He
* Sichang Tu
* Liayn Xu
* Zihao Wang

### 05/16/2022

* Kaustubh Dhole
* James Finch
* Sarah Finch
* Han He
* Sichang Tu
* Liayn Xu
* Zihao Wang

### 05/23/2022

* Kaustubh Dhole
* James Finch
* Sarah Finch
* Han He
* Sichang Tu
* Liayn Xu
* Zihao Wang

### 05/30/2022

* Kaustubh Dhole
* James Finch
* Sarah Finch
* Han He
* Sichang Tu
* Liayn Xu
* Zihao Wang

